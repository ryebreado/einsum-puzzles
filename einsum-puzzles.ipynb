{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1cd6ce1-233a-4330-9e08-ba9891ca021d",
      "metadata": {},
      "source": [
        "# Einsum Puzzles\n",
        "This Colab will teach you how to use numpy.einsum through examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f07eef4-42ae-4f89-97f7-e6969a9d0394",
      "metadata": {},
      "outputs": [],
      "source": [
        "# einsum is available in numpy, torch and JAX, so the following would all work:\n",
        "# np.einsum, torch.einsum, jnp.einsum\n",
        "# Let's start with numpy.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def check_answer(expected, given):\n",
        "  if expected.shape != given.shape:\n",
        "    print(\"Shape mismatch!\")\n",
        "    print(f\"Expected shape: {expected.shape}\")\n",
        "    print(f\"Given shape: {given.shape}\")\n",
        "    return\n",
        "  if np.allclose(expected, given):\n",
        "    print(\"Correct!\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Incorrect!\")\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a0ca998a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This visualization code is experimental and only works for tensors of rank up to 2.\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "def visualize_einsum(\n",
        "    einsum_str,\n",
        "    tensor_names=None,\n",
        "    tensor_shapes=None,\n",
        "    result_shape=None,\n",
        "    result_rank=None,\n",
        "    width_px=300):\n",
        "    \"\"\"\n",
        "    Generate a SVG visualization of tensors and their dimensions, with configurable width.\n",
        "    Ensures complete visibility of the visualization.\n",
        "    \"\"\"\n",
        "    # Parse the einsum string\n",
        "    input_output = einsum_str.split(\"->\")\n",
        "    inputs = input_output[0].split(\",\")\n",
        "    output = input_output[1] if len(input_output) > 1 else \"\"\n",
        "\n",
        "    if tensor_names is None:\n",
        "        tensor_names = [chr(65 + i) for i in range(len(inputs))]\n",
        "    if len(tensor_names) < len(inputs):\n",
        "        tensor_names.extend([chr(65 + i) for i in range(len(tensor_names), len(inputs))])\n",
        "\n",
        "    # SVG parameters with explicit aspect ratio control\n",
        "    tensor_width_wide = 60\n",
        "    tensor_height_wide = 60\n",
        "    tensor_width_narrow = tensor_width_wide // 3\n",
        "    tensor_height_narrow = tensor_height_wide // 3\n",
        "    arrow_margin = 30\n",
        "    label_margin = 20\n",
        "    spacing = 100\n",
        "\n",
        "    # Calculate total dimensions needed\n",
        "    total_width = spacing * (len(inputs) + 1) + arrow_margin * 2\n",
        "    total_height = tensor_height_wide + arrow_margin * 2 + label_margin * 2\n",
        "\n",
        "    # Scale factor based on desired width\n",
        "    scale_factor = width_px / total_width\n",
        "    scaled_height = int(total_height * scale_factor)\n",
        "\n",
        "    svg = f'''<svg viewBox=\"0 0 {total_width} {total_height}\"\n",
        "              xmlns=\"http://www.w3.org/2000/svg\"\n",
        "              width=\"{width_px}\"\n",
        "              height=\"{scaled_height}\"\n",
        "              style=\"margin: 10px;\">\\n'''\n",
        "\n",
        "    svg += '''    <defs>\n",
        "        <marker id=\"arrowhead\" markerWidth=\"6\" markerHeight=\"4\"\n",
        "                refX=\"6\" refY=\"2\" orient=\"auto\">\n",
        "            <polygon points=\"0 0, 6 2, 0 4\" fill=\"black\"/>\n",
        "        </marker>\n",
        "    </defs>\\n'''\n",
        "\n",
        "    # Starting positions\n",
        "    start_x = arrow_margin\n",
        "    start_y = arrow_margin\n",
        "\n",
        "    # Draw input tensors\n",
        "    for i, (indices, name) in enumerate(zip(inputs, tensor_names)):\n",
        "        tensor_width = tensor_width_wide\n",
        "        tensor_height = tensor_height_wide\n",
        "\n",
        "        shape = None\n",
        "        if tensor_shapes is not None:\n",
        "            shape = tensor_shapes[i]\n",
        "\n",
        "        is_vector = len(indices) == 1\n",
        "        if is_vector and shape is None or shape == \"v\":\n",
        "            tensor_width = tensor_width_narrow\n",
        "        if is_vector and shape == \"h\":\n",
        "            tensor_height = tensor_height_narrow\n",
        "\n",
        "        x = start_x + i * spacing\n",
        "\n",
        "        # Rectangle\n",
        "        svg += f'    <rect x=\"{x}\" y=\"{start_y}\" width=\"{tensor_width}\" height=\"{tensor_height}\" '\n",
        "        svg += 'fill=\"#e6f3ff\" stroke=\"black\" stroke-width=\"1\"/>\\n'\n",
        "\n",
        "        # Name\n",
        "        svg += f'    <text x=\"{x + tensor_width/2}\" y=\"{start_y + tensor_height/2}\" '\n",
        "        svg += 'text-anchor=\"middle\" dominant-baseline=\"middle\" '\n",
        "        svg += f'font-size=\"14\">{name}</text>\\n'\n",
        "\n",
        "        # Dimension arrows and labels\n",
        "        for j, idx in enumerate(indices):\n",
        "            if j == 0:  # Vertical\n",
        "                svg += f'    <line x1=\"{x-20}\" y1=\"{start_y}\" x2=\"{x-20}\" '\n",
        "                svg += f'y2=\"{start_y+tensor_height}\" stroke=\"black\" '\n",
        "                svg += 'marker-end=\"url(#arrowhead)\"/>\\n'\n",
        "                svg += f'    <text x=\"{x-10}\" y=\"{start_y + tensor_height/2}\" '\n",
        "                svg += f'text-anchor=\"middle\" font-size=\"12\">{idx}</text>\\n'\n",
        "            else:  # Horizontal\n",
        "                svg += f'    <line x1=\"{x}\" y1=\"{start_y+tensor_height+20}\" '\n",
        "                svg += f'x2=\"{x+tensor_width}\" y2=\"{start_y+tensor_height+20}\" '\n",
        "                svg += 'stroke=\"black\" marker-end=\"url(#arrowhead)\"/>\\n'\n",
        "                svg += f'    <text x=\"{x + tensor_width/2}\" y=\"{start_y+tensor_height+35}\" '\n",
        "                svg += f'text-anchor=\"middle\" font-size=\"12\">{idx}</text>\\n'\n",
        "\n",
        "    # Draw output tensor\n",
        "    is_scalar = result_rank is not None and result_rank == 0\n",
        "    if output or is_scalar:\n",
        "        tensor_width = tensor_width_wide\n",
        "        tensor_height = tensor_height_wide\n",
        "        name = \"r\"\n",
        "\n",
        "        is_vector = len(output) == 1\n",
        "        if is_vector and result_shape is None or result_shape == \"v\":\n",
        "            tensor_width = tensor_width_narrow\n",
        "        if is_vector and result_shape == \"h\":\n",
        "            tensor_height = tensor_height_narrow\n",
        "\n",
        "        if is_scalar:\n",
        "            # Special case of a scalar output\n",
        "            tensor_height = tensor_height_narrow\n",
        "            tensor_width = tensor_width_narrow\n",
        "\n",
        "        x = start_x + len(inputs) * spacing\n",
        "\n",
        "        svg += f'    <rect x=\"{x}\" y=\"{start_y}\" width=\"{tensor_width}\" height=\"{tensor_height}\" '\n",
        "        svg += 'fill=\"#ffe6e6\" stroke=\"black\" stroke-width=\"1\"/>\\n'\n",
        "\n",
        "        svg += f'    <text x=\"{x + tensor_width/2}\" y=\"{start_y + tensor_height/2}\" '\n",
        "        svg += f'text-anchor=\"middle\" dominant-baseline=\"middle\" font-size=\"14\">{name}</text>\\n'\n",
        "\n",
        "        if not is_scalar:\n",
        "            for j, idx in enumerate(output):\n",
        "                if j == 0 and result_shape != \"h\":  # Vertical\n",
        "                    svg += f'    <line x1=\"{x-20}\" y1=\"{start_y}\" x2=\"{x-20}\" '\n",
        "                    svg += f'y2=\"{start_y+tensor_height}\" stroke=\"black\" '\n",
        "                    svg += 'marker-end=\"url(#arrowhead)\"/>\\n'\n",
        "                    svg += f'    <text x=\"{x-10}\" y=\"{start_y + tensor_height/2}\" '\n",
        "                    svg += f'text-anchor=\"middle\" font-size=\"12\">{idx}</text>\\n'\n",
        "                else:  # Horizontal\n",
        "                    svg += f'    <line x1=\"{x}\" y1=\"{start_y+tensor_height+20}\" '\n",
        "                    svg += f'x2=\"{x+tensor_width}\" y2=\"{start_y+tensor_height+20}\" '\n",
        "                    svg += 'stroke=\"black\" marker-end=\"url(#arrowhead)\"/>\\n'\n",
        "                    svg += f'    <text x=\"{x + tensor_width/2}\" y=\"{start_y+tensor_height+35}\" '\n",
        "                    svg += f'text-anchor=\"middle\" font-size=\"12\">{idx}</text>\\n'\n",
        "\n",
        "    svg += '</svg>'\n",
        "    return SVG(svg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a588a9cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# A version od einsum that also validates correctness of the result.\n",
        "\n",
        "import numpy as np\n",
        "import inspect\n",
        "\n",
        "def einsum(einsum_expr,\n",
        "           *tensors,\n",
        "           expected=None,\n",
        "           result_shape=None):\n",
        "    # Get the calling frame to inspect variable names\n",
        "    frame = inspect.currentframe().f_back\n",
        "\n",
        "    # Extract variable names from the calling context\n",
        "    context_vars = frame.f_locals\n",
        "\n",
        "    # Find the actual variable names by matching values\n",
        "    tensor_names = []\n",
        "    for tensor in tensors:\n",
        "        for var_name, var_value in context_vars.items():\n",
        "            if var_value is tensor:\n",
        "                tensor_names.append(var_name)\n",
        "                break\n",
        "        else:\n",
        "            # If we couldn't find the variable name, use a placeholder\n",
        "            tensor_names.append(f\"tensor_{len(tensor_names)}\")\n",
        "\n",
        "    # Perform the einsum operation\n",
        "    result = np.einsum(einsum_expr, *tensors)\n",
        "\n",
        "    if expected is not None and not check_answer(expected, result):\n",
        "      # Don't attempt visualization if the result is incorrect\n",
        "      return result\n",
        "\n",
        "    # Visualize the operation\n",
        "    result_rank = None\n",
        "    if expected is not None:\n",
        "      result_rank = expected.ndim\n",
        "    svg = visualize_einsum(einsum_expr,\n",
        "                           tensor_names=tensor_names,\n",
        "                           result_shape=result_shape,\n",
        "                           result_rank=result_rank)\n",
        "    if svg:\n",
        "      display(svg)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eceeabbf-7896-4a5c-abd0-38627cf0b536",
      "metadata": {},
      "source": [
        "`einsum` allows you to create operations in which multiple inputs (vectors, arrays, or more generally, tensors of any rank) are combined to create a single result. A typical call would look like this:\n",
        "```\n",
        "d = np.einsum(\"◻◻,◻◻◻,◻◻->◻◻\", a, b, c)\n",
        "```\n",
        "where `a`, `b`, and `c` are inputs and `d` is the result. The subscripts string `\"◻◻,◻◻◻,◻◻->◻◻\"` has two parts separated by `->`:\n",
        "- The left part describes the dimensions of the inputs. There will be one description per input and they are separated by commas.\n",
        "- The right part describes the dimensions of the result.\n",
        "\n",
        "Here's our first example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a8b3d3-6a11-47c1-8bb8-354eff5efd53",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_length = 5\n",
        "u = np.arange(vector_length)\n",
        "print(f\"{u.shape=}\")\n",
        "print(f\"u: {u}\")\n",
        "\n",
        "r = np.einsum(\"i->i\", u)\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r: {r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2084a408-6dd8-42bc-94bc-6c14432e84ce",
      "metadata": {},
      "source": [
        "In the example above, there is one input `u`, which is a vector. The left part of the subscripts string is `\"i\"`. The use of a single letter means that the input has one dimension. The output is also specified as `\"i\"`, so it ends up being identical to the input.\n",
        "\n",
        "The choice of the letter does't matter, so instead of `\"i\"` we could have used `\"x\"` or any other letter, and the result would be the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc60e1-71d4-4ce6-8025-fb1da0ac3632",
      "metadata": {},
      "outputs": [],
      "source": [
        "r = np.einsum(\"x->x\", u)\n",
        "print(f\"r: {r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5997867-52d4-42fa-b408-33f0cb6d7611",
      "metadata": {},
      "source": [
        "There is a shortcut for this operation. If we completely omit the `->` symbol and the right hand side, we can get as output the same vector as the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfc9acc-c6cb-4128-b9fd-7ae6637e33dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "r = np.einsum(\"i\", u)\n",
        "print(f\"r: {r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bdb2e17-5de9-422b-9c25-84b977363097",
      "metadata": {},
      "source": [
        "Another important feature of `einsum` is that if the same letter appears twice on the left-hand side, then corresponding elements from the two inputs on the dimension described by that letter will be pairwise multiplied by each other.\n",
        "\n",
        "In the example below, the result, `r`, is a vector of the same length as the two inputs `u` and `v`, and each of its elements is a product of two corresponding elements of `u` and `v`. That is, we want to compute `r` such that:\n",
        "\n",
        "$$\n",
        "r_i = u_i v_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827afb87-32f0-4db3-8a2f-94bbd37ab464",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"u: {u}\")\n",
        "v = np.arange(vector_length, 2 * vector_length)\n",
        "print(f\"v: {v}\")\n",
        "print(f\"{v.shape=}\")\n",
        "\n",
        "r = np.einsum(\"i,i->i\", u, v)\n",
        "print(f\"r: {r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d88c34c",
      "metadata": {},
      "source": [
        "# Verifying puzzle solutions\n",
        "\n",
        "In the rest of the tutorial instead of using the numpy function `np.einsum`, we will use the function `einsum` defined earlier in this notebook. This function also performs validation with the expected answer, so we can check in the puzzles if the provided answer was correct. For example we can check if the sum of all elements in one the earlier examples is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba973ec3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the expected result using another method, in this case the np.sum function.\n",
        "r = einsum(\"i->\", u, expected=np.sum(u))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e76f251-dfe3-44b5-a00e-f53a8270cfa2",
      "metadata": {},
      "source": [
        "# Puzzle 1: inner product\n",
        "\n",
        "Use your knowledge from the previous two examples to compute the inner product of `u` and `v`, that is, compute the sum of the pairwise products of the elements of `u` and `v`. Remember that:\n",
        "- Repeating the same index twice on the left-hand side of `->` means that elements will be pairwise multiplied.\n",
        "- Omitting an index on the right-hand side of `->` means that we will sum all values along that dimension.\n",
        "\n",
        "The inner product is also implemented as `np.inner` and we will use that function to check the correctness of the answer.\n",
        "\n",
        "The result should be:\n",
        "\n",
        "$$\n",
        "r = \\sum_i u_i v_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b6228e-36d7-4fc9-9256-59e3c27fd13c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"u: {u}\")\n",
        "print(f\"v: {v}\")\n",
        "\n",
        "# Fill in the first argument to the np.einsum call below:\n",
        "r = einsum(\"\", u, v, expected=np.inner(u, v))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89150119-d7c0-4cea-a1ae-d41c06f1f919",
      "metadata": {},
      "source": [
        "The same principle applies to matrices. Consider this snippet, which doesn't change the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a74f03a-1754-4e25-9252-62cf6664e567",
      "metadata": {},
      "outputs": [],
      "source": [
        "rows, cols = 3, 4\n",
        "a = np.arange(rows * cols).reshape(rows, cols)\n",
        "print(f\"{a.shape=}\")\n",
        "print(f\"a:\\n{a}\")\n",
        "\n",
        "r = einsum(\"ij->ij\", a)\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r:\\n{r}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96d3359-302e-4eaf-b060-1c47daa23666",
      "metadata": {},
      "source": [
        "# Puzzle 2: matrix transpose\n",
        "\n",
        "Since the order of letters in the subscripts string determines the order of dimensions, you can take advantage of that to permute dimensions of a tensor. How would you use that to transpose a matrix? Fill in the subscripts string below to solve this puzzle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560d6fac-8533-4e53-b566-0c9e69582581",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in the first argument to the np.einsum call below:\n",
        "r = einsum(\"\", a, expected=a.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea73f271-453b-4e52-9972-39e2471625dd",
      "metadata": {},
      "source": [
        "To summarize what we've learned so far:\n",
        "\n",
        "- Letters that appear in the subscripts string both to the left and right of the `\"->\"` arrow are called *free indices*. They indicate no change in the dimensions denoted by those indices.\n",
        "\n",
        "- If an index appears to the left of `\"->\"` but not to the right, it is called a *summation index* and `einsum` will add all values along that dimension. For example, we can use this to calculate the sum of all elements of our vector `u`.\n",
        "\n",
        "- If an index appears twice on the left hand side, we will perform pairwise multiplication of the corresponding elements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4071f8d-10e4-4a3d-acb6-0fa9faf3da35",
      "metadata": {},
      "source": [
        "Consider another summation example. This time, we have a matrix with 3 rows and 4 columns and we want to add all elements in each row. The result is a vector of three elements, in which the first element is the sum of all 4 elements in the first row of the array, and so on:\n",
        "\n",
        "$$\n",
        "r_i = \\sum_j a_{ij}\n",
        "$$\n",
        "\n",
        "We do this by not writing the column dimension (denoted by `j`) on the right-hand side:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5988628e-a758-4e63-bb95-58a1e0411622",
      "metadata": {},
      "outputs": [],
      "source": [
        "rows, cols = 3, 4\n",
        "a = np.arange(rows * cols).reshape(rows, cols)\n",
        "print(f\"{a.shape=}\")\n",
        "print(f\"a:\\n{a}\")\n",
        "\n",
        "r = einsum(\"ij->i\", a)\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r:\\n{r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfaca732-0083-4540-83d9-831d67b8b640",
      "metadata": {},
      "source": [
        "# Puzzle 3: Summing columns of an array\n",
        "\n",
        "How would you create a vector containing the sum of each column in the matrix? For our matrix with 3 rows and 4 columns, the result should be a vector of 4 elements, in which each element is the sum of the values in the corresponding column.\n",
        "\n",
        "$$\n",
        "r_j = \\sum_i a_{ij}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38cb6631-c4b5-4411-ba23-3c71a83e16d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in the first argument to the np.einsum call below:\n",
        "r = einsum(\"\", a, expected=np.sum(a, axis=0))\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r:\\n{r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389f986a-858f-4d05-b3a8-a7c5d6e74f51",
      "metadata": {},
      "source": [
        "# A note on vectors in this colab\n",
        "\n",
        "Some of the examples operate on vectors and matrices. Depending on the type of operation, the vector will be either a row vector or a column vector. However, when Python prints a numpy vector, it is always printed in a single line of text, which makes it look like a row vector. If you want to figure out whether the vector is a row or column vector, you will need to use your knowledge of linear algebra.\n",
        "\n",
        "The two most common operations we will encounter are:\n",
        "- Multiplication of a vector by matrix: The vector is a *row vector* with length equal to the number of rows of the matrix. The result is a *row vector*.\n",
        "- Multiplication of a matrix by a vector: The vector is a *column vector* with length equal to the number of columns of the matrix. The result is a *column vector*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adb2b2f-6ed2-40cd-947b-1734a16868b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a matrix and two vectors with lengths matching the number of rows and\n",
        "# the number of columns in the matrix, respectively.\n",
        "\n",
        "rows, cols = 3, 4\n",
        "a = np.arange(rows * cols).reshape(rows, cols)\n",
        "print(f\"{a.shape=}\")\n",
        "print(f\"a:\\n{a}\")\n",
        "\n",
        "u = np.arange(cols)\n",
        "print(f\"{u.shape=}\")\n",
        "print(f\"u: {u}\")\n",
        "\n",
        "w = np.arange(rows)\n",
        "print(f\"{w.shape=}\")\n",
        "print(f\"w: {w}\")\n",
        "\n",
        "print(\"\\nVector multiplied by matrix (the result is a row vector)\")\n",
        "wxa = w @ a\n",
        "print(f\"{wxa.shape=}\")\n",
        "print(f\"wxa: {wxa}\")\n",
        "\n",
        "\n",
        "print(\"\\nMatrix multiplied by vector (the result is a column vector)\")\n",
        "axu = a @ u\n",
        "print(f\"{axu.shape=}\")\n",
        "print(f\"axu: {axu}\")\n",
        "\n",
        "print(\"\\nUse matrix transpose to compute wxa as a column vector.\")\n",
        "wxa2 = a.T @ w\n",
        "print(f\"{wxa2.shape=}\")\n",
        "print(f\"wxa2:\\n{wxa2}\")\n",
        "print(\"In math, vectors wxa and wxa2 are row and column vectors, respectively.\")\n",
        "print(\"But in Python, they're printed the same way and have the same shape.\")\n",
        "\n",
        "print(\"\\nThese two vectors are equal to each other.\")\n",
        "print(f\"{np.array_equal(wxa, wxa2)=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aad8eb2-b29f-4c57-b78b-a8afc67fa738",
      "metadata": {},
      "source": [
        "# Puzzle 4: Multiply a matrix by a vector\n",
        "\n",
        "How would you multiply a matrix by a vector? The vector has length equal to the number of columns in the matrix and the result is a vector with length equal to the number of rows of the matrix.\n",
        "\n",
        "So, the $i$th element of the result can be expressed as:\n",
        "$$\n",
        "r_i = \\sum_j a_{ij}u_j\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acc4143-9bc1-44d1-8ae9-a9926ed23d7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in the first argument to the np.einsum call below:\n",
        "r = einsum(\"ij,j->i\", a, u, expected=a @ u)\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r:\\n{r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f07f16-3b6a-4ab1-bf0f-355bde5f3ff4",
      "metadata": {},
      "source": [
        "# Puzzle 5: Matrix multiplication\n",
        "\n",
        "Given what we've learned so far about `einsum`, matrix multiplication can be expressed in an elegant way. We need to perform an inner product along two matching dimensions, which we already did in Puzzle 1. The other two dimensions are unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5acdd16-9e34-4335-9672-3988b77d1e9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "rows2 = cols\n",
        "cols2 = 5\n",
        "b = np.arange(rows2 * cols2).reshape(rows2, cols2)\n",
        "\n",
        "# Fill in the first argument to the np.einsum call below.\n",
        "r = einsum(\"\", a, b, expected=a @ b)\n",
        "print(f\"{r.shape=}\")\n",
        "print(f\"r:\\n{r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed61f4b5-aa27-45a6-afbe-9e1133b9f8b3",
      "metadata": {},
      "source": [
        "# Puzzle 6: Part of the attention kernel\n",
        "\n",
        "We will now look at a formula from the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper. A part of the implementation of transformers computes this formula:\n",
        "\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right)V\n",
        "$$\n",
        "\n",
        "For this puzzle, try to implement a small part of this formula:\n",
        "\n",
        "$$\n",
        "S = QK^T\n",
        "$$\n",
        "\n",
        "The nice thing about using `einsum` is that the whole operation can be performed in a single call. Without `einsum`, we need to first transpose $K$ and then multiply that with $Q$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ce6013-22f5-4df4-940e-3033870b23d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume that Q and K are matrices (tensors of rank 2).\n",
        "\n",
        "np.random.seed(42)\n",
        "Q = np.random.rand(4, 5)  # Query matrix (4 examples, 5 dimensions)\n",
        "K = np.random.rand(4, 5)  # Key matrix (4 examples, 5 dimensions)\n",
        "\n",
        "# Fill in the first argument to the np.einsum call below. It should be similar\n",
        "# to what you did for matrix multiplication.\n",
        "scores = einsum(\"\", Q, K, expected=Q @ K.T)\n",
        "print(f\"{scores.shape=}\")\n",
        "print(f\"scores:\\n{scores}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
